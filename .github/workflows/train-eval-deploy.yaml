name: Nizami-1.7B-LLMOps

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  HF_TOKEN:        ${{ secrets.HF_TOKEN }}
  WANDB_API_KEY:   ${{ secrets.WANDB_API_KEY }}
  KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
  KAGGLE_KEY:      ${{ secrets.KAGGLE_KEY }}
  MODEL_ID:        Rustamshry/Qwen3-CoT

jobs:
  train-on-kaggle:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Kaggle API
        run: pip install kaggle

      - name: Push & trigger Kaggle notebook
        run: python kaggle/push_notebook.py

      - name: Wait until kernel finishes
        run: |
          pip install kaggle
          python -c "
          import os, time, kaggle
          kaggle.api.authenticate()
          slug = os.environ['KAGGLE_USERNAME'] + '/nizami-1-7b-cot-train'
          while True:
              status = kaggle.api.kernels_status(slug).status
              status_str = status.value 
              print('Kernel status:', status_str)
              if status_str in [2, 3, 4]: 
                  break
              time.sleep(30)
          if status_str != 2: exit(1)
          "

  evaluate:
    needs: train-on-kaggle
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with: {python-version: '3.10'}
        
      - name: Wait 1 minute before downloading dataset
        run: sleep 60
        
      - name: Install Kaggle API
        run: pip install kaggle

      - name: Download model from Kaggle Dataset
        run: |
          mkdir -p ./outputs
          kaggle datasets download -d rustamshiriyev/nizami-model-output --unzip -p ./outputs
          # Dataset ZIP içinde klasör yapısı düzeltme
          if [ -d "./outputs/nizami-model-output" ]; then
            mv ./outputs/nizami-model-output/outputs/* ./outputs/ 2>/dev/null || true
            rmdir ./outputs/nizami-model-output/outputs 2>/dev/null || true
            rmdir ./outputs/nizami-model-output 2>/dev/null || true
          fi
          # Veya doğrudan outputs varsa:
          if [ ! -f "./outputs/adapter_config.json" ]; then
            echo "  WARNING: ./outputs may be empty or malformed"
          fi
      - run: pip install -r docker/requirements.txt
      - run: python src/evaluate_llm.py
      - uses: actions/upload-artifact@v4
        with:
          name: metrics
          path: metrics.json
      - uses: actions/upload-artifact@v4
        with:
          name: model-adapter
          path: ./outputs   

  push-hub:
    needs: evaluate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with: {python-version: '3.10'}
      - uses: actions/download-artifact@v4
        with:
          name: model-adapter
          path: ./outputs
      - uses: actions/download-artifact@v4
        with:
          name: metrics
          path: .
      - run: pip install -r docker/requirements.txt
      - run: python scripts/upload_model.py

  docker-build-and-push:
    needs: push-hub
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile
          push: true
          tags: |
            ghcr.io/rustamshry34/llmops:latest
            ghcr.io/rustamshry34/llmops:${{ github.sha }}

  deploy-aws:
    needs: docker-build-and-push
    runs-on: ubuntu-latest
    environment: production  # opsiyonel: env koruması için
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.0"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-north-1  # sabit ya da secret'ten al

      - name: Generate SSH key pair
        run: |
          mkdir -p ~/.ssh
          ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa -N ""
          echo "TF_VAR_public_key_path=~/.ssh/id_rsa.pub" >> $GITHUB_ENV
          # Terraform'da file() fonksiyonu için public key'i doğrudan env'e yaz
          echo "PUBLIC_KEY_CONTENT=$(cat ~/.ssh/id_rsa.pub)" >> $GITHUB_ENV

      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform

      - name: Terraform Apply
        run: |
          terraform apply -auto-approve \
            -var="github_repo=rustamshry34/llmops" \
            -var="docker_image_tag=latest" \
            -var="hf_model_id=Rustamshry/Qwen3-CoT" \
            -var="region=eu-north-1"
        working-directory: ./terraform

      - name: Get Terraform Outputs
        id: tf-outputs
        run: |
          cd ./terraform
          echo "EC2_IP=$(terraform output -raw instance_public_ip)" >> $GITHUB_OUTPUT
          echo "INFERENCE_URL=$(terraform output -raw inference_endpoint)" >> $GITHUB_OUTPUT

      - name: Print Inference Endpoint
        run: |
          echo "✅ Model deployed! Inference API: ${{ steps.tf-outputs.outputs.INFERENCE_URL }}"
